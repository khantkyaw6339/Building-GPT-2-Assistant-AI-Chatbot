{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9sdm_yjmD1Tj"},"outputs":[],"source":["!pip install datasets\n","!pip install transformers[torch]\n","!pip install accelerate -U"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9t2xQlHCEa3U"},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n","from datasets import Dataset, load_dataset\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MG-JnVQnEbNl"},"outputs":[],"source":["# Initialize tokenizer and model\n","model_name = 'gpt2'\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'sep_token': '<SEP>', 'pad_token': '<PAD>'}\n","tokenizer.add_special_tokens(special_tokens_dict)\n","\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n_EceK6_EbfH"},"outputs":[],"source":["def load_and_prepare_data(file_path, tokenizer):\n","    \"\"\"Load and prepare the dataset for a chatbot fine-tuning task.\"\"\"\n","    # Load the dataset from the CSV file\n","    dataset = load_dataset('csv', data_files=file_path)\n","\n","    # Function to concatenate question and answer for the tokenizer\n","    def tokenize_qa(examples):\n","        # Concatenate the question and answer with a separator\n","        # You might consider adding special tokens or separators if it helps your model\n","        qa_pairs = [f\"<BOS> [User] {q} <SEP> [Bot] {a} <EOS>\" for q, a in zip(examples['instruction'], examples['output'])]\n","        return tokenizer(qa_pairs, padding='max_length', truncation=True, max_length=512)\n","\n","\n","    # Apply tokenization to each QA pair in the dataset\n","    tokenized_datasets = dataset.map(tokenize_qa, batched=True)\n","    tokenized_datasets = tokenized_datasets.remove_columns([\"instruction\", \"output\"])\n","    return tokenized_datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZ2Avvw2Eb0d"},"outputs":[],"source":["file_paths = {\n","    \"train\": '/content/drive/MyDrive/df_train.csv',\n","    \"validation\": '/content/drive/MyDrive/df_val.csv'\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"acnhc0zWEcG2"},"outputs":[],"source":["# Load and prepare the datasets\n","datasets = load_and_prepare_data(file_paths, tokenizer)\n","train_dataset = datasets['train']\n","val_dataset = datasets['validation']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvJ6nWIdEcUE"},"outputs":[],"source":["# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    overwrite_output_dir=True,\n","    num_train_epochs=4,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    logging_dir='./logs',\n","    logging_steps=100,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=500,  # Evaluate every 500 steps\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"loss\",\n",")\n","\n","# Initialize Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CjWS0AUkEclM"},"outputs":[],"source":["# Train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eV-Q3VmuEc5f"},"outputs":[],"source":["model.save_pretrained('./gpt2_chatbot')\n","tokenizer.save_pretrained('./gpt2_chatbot')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kv8eFJ94EdPd"},"outputs":[],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxBaMeBqEdnk"},"outputs":[],"source":["tokenizer.push_to_hub(\"\") #pushing tokenizeer to Huggingface "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ck5Ax8LVEd6E"},"outputs":[],"source":["model.push_to_hub(\"\") ##pushing model to Huggingface "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNgbLE2zL1OU4N7gS7eNtLx","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
